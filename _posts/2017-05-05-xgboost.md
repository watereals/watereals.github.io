---
layout: post
title: xgboost使用
mathjax: true
---

# Xgboost

## 安装xgboost

编译好的window文件：[xgboost-windows-x64-binaries-for-download](http://www.picnet.com.au/blogs/guido/post/2016/09/22/xgboost-windows-x64-binaries-for-download/)

[Installing_XGBoost_For_Anaconda_on_Windows](https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=zh) (在Win7+Anaconda2上安装成功，安装TDM-GCC时需要勾选OpenMP)

https://www.zhihu.com/question/46377605?sort=created

Github of xgboost: [XGBoost Github](https://github.com/dmlc/xgboost)

官方安装与使用文档: [XGBoost Documents](https://xgboost.readthedocs.io/en/latest/)

## 测试

运行xgboost/demo/guide-python/中的一段code:

```python
#!/usr/bin/python
import numpy as np
import scipy.sparse
import pickle
import xgboost as xgb

### simple example
# load file from text file, also binary buffer generated by xgboost
dtrain = xgb.DMatrix('../data/agaricus.txt.train')
dtest = xgb.DMatrix('../data/agaricus.txt.test')

# specify parameters via map, definition are same as c++ version
param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }

# specify validations set to watch performance
watchlist  = [(dtest,'eval'), (dtrain,'train')]
num_round = 2
bst = xgb.train(param, dtrain, num_round, watchlist)

# this is prediction
preds = bst.predict(dtest)
labels = dtest.get_label()
print ('error=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))))
```

测试结果：

```shell
$ python test.py
[23:08:11] 6513x127 matrix with 143286 entries loaded from ../data/agaricus.txt.train
[23:08:12] 1611x127 matrix with 35442 entries loaded from ../data/agaricus.txt.test
[0]     eval-error:0.042831     train-error:0.046522
[1]     eval-error:0.021726     train-error:0.022263
error=0.021726
```
